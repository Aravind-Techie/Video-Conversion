{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37197c5-50cb-45d9-be25-76389e3d3787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video vertical_video.mp4.\n",
      "MoviePy - Writing audio in vertical_videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video vertical_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready vertical_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "from moviepy.video.fx.all import crop\n",
    "\n",
    "def detect_action_frame(frame):\n",
    "    \"\"\"\n",
    "    Detects the region of interest (ROI) where the action is happening.\n",
    "    Here, a simplistic center crop is performed.\n",
    "    You can improve this by integrating object detection/tracking algorithms.\n",
    "    \"\"\"\n",
    "    height, width, _ = frame.shape\n",
    "    roi_width = int(width * 0.5)  # Crop width (50% of original width)\n",
    "    roi_height = height           # Use full height\n",
    "    \n",
    "    # Assuming action is centered; modify if object detection is integrated\n",
    "    x_center = width // 2\n",
    "    y_center = height // 2\n",
    "    \n",
    "    x1 = max(0, x_center - roi_width // 2)\n",
    "    x2 = min(width, x_center + roi_width // 2)\n",
    "    \n",
    "    return x1, x2, 0, height\n",
    "\n",
    "def convert_to_vertical(input_video, output_video):\n",
    "    \"\"\"\n",
    "    Converts a horizontal video to a vertical one (9:16) using a 'follow the action' approach.\n",
    "    Preserves and synchronizes the audio track.\n",
    "    \"\"\"\n",
    "    # Load video and audio using moviepy\n",
    "    video = mp.VideoFileClip(input_video)\n",
    "    audio = video.audio\n",
    "    \n",
    "    # Get original resolution\n",
    "    original_width, original_height = video.size\n",
    "    \n",
    "    # Target vertical resolution (9:16)\n",
    "    target_width = 1080\n",
    "    target_height = 1920\n",
    "    \n",
    "    # Calculate the scaling factor to maintain aspect ratio\n",
    "    scaling_factor = target_width / original_width\n",
    "    new_height = int(original_height * scaling_factor)\n",
    "    \n",
    "    # Resize the video\n",
    "    resized_video = video.resize(width=target_width)\n",
    "    \n",
    "    # Crop dynamically based on the 'follow the action' approach\n",
    "    frames = []\n",
    "    for frame in resized_video.iter_frames():\n",
    "        x1, x2, y1, y2 = detect_action_frame(frame)\n",
    "        cropped_frame = frame[y1:y2, x1:x2]\n",
    "        frames.append(cropped_frame)\n",
    "    \n",
    "    # Convert back to a moviepy video clip\n",
    "    action_video = mp.ImageSequenceClip(frames, fps=video.fps)\n",
    "    \n",
    "    # Resize the cropped video to the target 9:16 format\n",
    "    final_video = action_video.resize((target_width, target_height))\n",
    "    \n",
    "    # Set the audio of the final video\n",
    "    final_video = final_video.set_audio(audio)\n",
    "    \n",
    "    # Export the video with audio\n",
    "    final_video.write_videofile(output_video, codec='libx264', audio_codec='aac', fps=24)\n",
    "\n",
    "# Example usage\n",
    "input_video = \"input.mp4\"\n",
    "output_video = \"vertical_video.mp4\"\n",
    "convert_to_vertical(input_video, output_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0eee4c-a217-4864-8a74-8aee419f905e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
